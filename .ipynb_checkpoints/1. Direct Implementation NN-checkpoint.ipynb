{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3354a7df",
   "metadata": {},
   "source": [
    "## Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2726e9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59865848 0.15601864 0.15599452]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuron(object):\n",
    "    def __init__(self,num_inputs,activation_fn):\n",
    "        self.W=np.random.rand(num_inputs) # weight\n",
    "        self.b=np.random.rand(1) # bias\n",
    "        self.activation_fn=activation_fn\n",
    "        \n",
    "    def forward(self,x):\n",
    "        z=np.dot(x,self.W) + self.b\n",
    "        return self.activation_fn(z)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x=np.random.rand(3).reshape(1,3)\n",
    "\n",
    "step_fn=lambda y: 0 if y <=0 else 1 # step function\n",
    "\n",
    "perceptron=Neuron(num_inputs=x.size,activation_fn=step_fn)\n",
    "print(perceptron.W)\n",
    "out=perceptron.forward(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5111905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.25091976  0.90142861]]\n",
      "[[0.46398788 0.19731697]]\n",
      "[[0.9323663  0.         0.39706569]]\n",
      "[[0.22460853 0.         1.14403416]]\n",
      "[[0.9323663  0.         0.39706569]\n",
      " [0.22460853 0.         1.14403416]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FullyConnectLayer(object):\n",
    "    def __init__(self,num_inputs,layer_size,activation_fn):\n",
    "        self.W=np.random.standard_normal((num_inputs,layer_size)) # weight\n",
    "        self.b=np.random.rand(layer_size) # bias\n",
    "        self.size=layer_size\n",
    "        self.activation_fn=activation_fn\n",
    "        \n",
    "    def forward(self,x):\n",
    "        z=np.dot(x,self.W) + self.b\n",
    "        return self.activation_fn(z)\n",
    "np.random.seed(42)\n",
    "x1=np.random.uniform(-1,1,2).reshape(1,2)\n",
    "print(x1)\n",
    "x2=np.random.uniform(-1,1,2).reshape(1,2)\n",
    "print(x2)\n",
    "\n",
    "relu_fn=lambda y: np.maximum(y,0) #relu functioin\n",
    "layer=FullyConnectLayer(2,3,relu_fn)\n",
    "out1=layer.forward(x1)\n",
    "print(out1)\n",
    "out2=layer.forward(x2)\n",
    "print(out2)\n",
    "\n",
    "x12=np.concatenate((x1,x2))\n",
    "out12=layer.forward(x12)\n",
    "print(out12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf77a94",
   "metadata": {},
   "source": [
    "## Using MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "836d197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "data_train, data_test = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12ecf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (60000, 28, 28)\n",
      "test (10000, 28, 28)\n",
      "after reshape\n",
      "train (60000, 784)\n",
      "test (10000, 784)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train)=data_train\n",
    "(x_test,y_test)=data_test\n",
    "num_classes=10\n",
    "\n",
    "print('train',x_train.shape)\n",
    "print('test',x_test.shape)\n",
    "x_train,x_test=x_train.reshape(-1,28*28),x_test.reshape(-1,28*28)\n",
    "print('after reshape')\n",
    "print('train',x_train.shape)\n",
    "print('test',x_test.shape)\n",
    "y_train=np.eye(num_classes)[y_train]\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd227432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(value):\n",
    "    return 1.0/ (1.0 + np.exp(-value))\n",
    "\n",
    "class SimpleNN(object):\n",
    "    \n",
    "    def __init__(self,num_inputs,num_outputs,hidden_layers_size=(64,32)):\n",
    "        super().__init__()\n",
    "        sizes=[num_inputs,*hidden_layers_size,num_outputs] # NeuralNet\n",
    "        self.layers=[FullyConnectLayer(sizes[i],sizes[i+1],sigmoid) for i in range(len(sizes)-1)]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x=layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        estimations=self.forward(x)\n",
    "        best_class=np.argmax(estimations)\n",
    "        return best_class\n",
    "    \n",
    "    def evaluate_accuracy(self,x_val,y_val): # valid test\n",
    "        num_corrects=0\n",
    "        for i in range(len(x_val)):\n",
    "            if self.predict(x_val[i])==y_val[i]:\n",
    "                num_corrects+=1\n",
    "            return num_corrects/len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2b8d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier=SimpleNN(x_train.shape[1],num_classes,[64,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8db5f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_6160/578090442.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/ (1.0 + np.exp(-value))\n"
     ]
    }
   ],
   "source": [
    "accuracy=mnist_classifier.evaluate_accuracy(x_test,y_test)\n",
    "print('accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf4ec747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(object):\n",
    "    def __init__(self,num_inputs,layer_size,activation_fn,d_activation_fn):\n",
    "        self.W=np.random.standard_normal((num_inputs,layer_size)) # weight\n",
    "        self.b=np.random.rand(layer_size) # bias\n",
    "        self.size=layer_size\n",
    "        self.activation_fn=activation_fn\n",
    "        self.d_activation_fn=d_activation_fn\n",
    "        self.x,self.y,self.dL_dW,self.dL_db=0,0,0,0\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        z=np.dot(x,self.W) + self.b\n",
    "        self.y=self.activation_fn(z)\n",
    "        self.x=x\n",
    "        return self.y\n",
    "    \n",
    "    def backward(self,dL_dy):\n",
    "        dy_dz=self.d_activation_fn(self.y)\n",
    "        dL_dz=(dL_dy*dy_dz)\n",
    "        dz_dw=self.x.T\n",
    "        dz_dx=self.W.T\n",
    "        dz_db=np.ones(dL_dy.shape[0])\n",
    "        self.dL_dW=np.dot(dz_dw,dL_dz)\n",
    "        self.dL_db=np.dot(dz_db,dL_dz)\n",
    "        dL_dx=np.dot(dL_dz,dz_dx)\n",
    "        return dL_dx\n",
    "    \n",
    "    def optimize(self,epsilon):\n",
    "        self.W-=epsilon*self.dL_dW\n",
    "        self.b-=epsilon*self.dL_db\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "643101cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivated_sigmoid(y):\n",
    "    return y*(1-y)\n",
    "\n",
    "def loss_L2(pred,target):\n",
    "    return np.sum(np.square(pred-target)) / pred.shape[0]\n",
    "\n",
    "def derivated_loss_L2(pred,target):\n",
    "    return 2*(pred-target)\n",
    "\n",
    "class SimpleNetwork(object):\n",
    "    def __init__(self,num_inputs,num_outputs,hidden_layers_size=(64,32),loss_fn=loss_L2,d_loss_fn=derivated_loss_L2):\n",
    "        super().__init__()\n",
    "        sizes=[num_inputs,*hidden_layers_size,num_outputs] # NeuralNet\n",
    "        self.layers=[FullyConnectedLayer(sizes[i],sizes[i+1],sigmoid,derivated_sigmoid) for i in range(len(sizes)-1)]\n",
    "        self.loss_fn,self.d_loss_fn=loss_fn,d_loss_fn\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x=layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        estimations=self.forward(x)\n",
    "        best_class=np.argmax(estimations)\n",
    "        return best_class\n",
    "    \n",
    "    def evaluate_accuracy(self,x_val,y_val): # valid test\n",
    "        num_corrects=0\n",
    "        for i in range(len(x_val)):\n",
    "            if self.predict(x_val[i])==y_val[i]:\n",
    "                num_corrects+=1\n",
    "#             print(num_corrects)\n",
    "            return num_corrects/len(x_val)\n",
    "        \n",
    "    def backward(self,dL_dy):\n",
    "        for layer in reversed(self.layers):\n",
    "            dL_dy=layer.backward(dL_dy)\n",
    "        return dL_dy\n",
    "    \n",
    "    def optimize(self,epsilon):\n",
    "        for layer in self.layers:\n",
    "            layer.optimize(epsilon)\n",
    "        \n",
    "    def train(self,x_train,y_train,x_val,y_val,batch_size=32,num_epochs=5,learning_rates=5e-3):\n",
    "        num_batches_per_epoch=len(x_train)//batch_size\n",
    "        loss,accuracy=[],[]\n",
    "        for i in range(num_epochs):\n",
    "            epoch_loss=0\n",
    "            for b in range(num_batches_per_epoch):\n",
    "                b_idx=b*batch_size\n",
    "                b_idx_e=b_idx+batch_size\n",
    "                x,y_true=x_train[b_idx:b_idx_e],y_train[b_idx:b_idx_e]\n",
    "                y=self.forward(x)\n",
    "                epoch_loss+=self.loss_fn(y,y_true)\n",
    "                dL_dy=self.d_loss_fn(y,y_true)\n",
    "                self.backward(dL_dy)\n",
    "                self.optimize(learning_rates)\n",
    "            loss.append(epoch_loss/num_batches_per_epoch)\n",
    "            accuracy.append(self.evaluate_accuracy(x_val,y_val))\n",
    "            print(\"Epoch\",i,\"loss\",loss[i],'accuracy',accuracy[i]*100)\n",
    "        \n",
    "        return loss,accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8fe9976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp/ipykernel_6160/578090442.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/ (1.0 + np.exp(-value))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 1.6016706026570116 accuracy 0.0\n",
      "Epoch 1 loss 0.8506987255459663 accuracy 0.01\n",
      "Epoch 2 loss 0.49663140106598014 accuracy 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6160/4251577474.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmnist_classifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSimpleNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuarcies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmnist_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6160/563507368.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, y_train, x_val, y_val, batch_size, num_epochs, learning_rates)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[0mepoch_loss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[0mdL_dy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_loss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdL_dy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_batches_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6160/563507368.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dL_dy)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdL_dy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mdL_dy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdL_dy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdL_dy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6160/2012975885.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dL_dy)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mdz_dx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mdz_db\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdL_dy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdL_dW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdz_dw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdL_dz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdL_db\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdz_db\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdL_dz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mdL_dx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdL_dz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdz_dx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mnist_classifier=SimpleNetwork(x_train.shape[1],num_classes,[64,32])\n",
    "losses,accuarcies=mnist_classifier.train(x_train,y_train,x_test,y_test,batch_size=30,num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc1e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
